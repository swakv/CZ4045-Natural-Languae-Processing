| | | | | | | | | | | | | | | | | | | | | | | US009776364B2( 12 ) United States PatentWang( 10 ) Patent No . :( 45 ) Date of Patent :US 9 , 776 , 364 B2Oct . 3 , 2017( 54 ) METHOD FOR INSTRUCTING A 3DPRINTING SYSTEM COMPRISING A 3DPRINTER AND 3D PRINTING SYSTEM N( 71 ) Applicant : Apple Inc . , Cupertino , CA ( US )7 , 113 , 270 B27 , 161 , 664 B27 , 203 , 384 B27 , 268 , 956 B27 , 343 , 216 B27 , 474 , 809 B27 , 729 , 515 B27 , 826 , 641 B27 , 961 , 909 B28 , 016 , 421 B28 , 113 , 657 B29 / 2006 Buermann et al .1 / 2007 Buermann et al .4 / 2007 Carl9 / 2007 Mandella3 / 2008 Swift1 / 2009 Carl et al .6 / 2010 Mandella et al .11 / 2010 Mandella et al .6 / 2011 Mandella et al .9 / 2011 Eberl2 / 2012 Eberl( Continued )( 72 ) Inventor : Lejing Wang , Munich ( DE )( 73 ) Assignee : Apple Inc . , Cupertino , CA ( US )( * ) Notice : Subject to any disclaimer , the term of thispatent is extended or adjusted under 35U . S . C . 154 ( b ) by 832 days . FOREIGN PATENT DOCUMENTSEP 2193825 A1 6 / 2010 ( 21 ) Appl . No . : 13 / 963 , 766( 22 ) Filed : Aug . 9 , 2013 OTHER PUBLICATIONS( 65 ) Prior Publication DataUS 2015 / 0042755 A1 Feb . 12 , 2015Wang , Lejing , et al . “ Parallax - free intra - operative X - ray imagestitching . " Medical Image Analysis 14 . 5 ( 2010 ) : 674 - 686 .( Continued )Primary Examiner - Michael Teitelbaum( 74 ) Attorney , Agent , or Firm — Blank Rome LLP( 51 ) Int . C1 .B29C 67 / 00 ( 2017 . 01 )H04N 13 / 02 ( 2006 . 01 )H04N 13 / 00 ( 2006 . 01 )U . S . CI .CPC . . . . . . B29C 6770088 ( 2013 . 01 ) ; H04N 13 / 0203( 2013 . 01 ) ; H04N 2013 / 0081 ( 2013 . 01 )( 58 ) Field of Classification SearchCPC . . . . . . B29C 2795 / 00 – 2795 / 007 ; B29C 67 / 0051 ;B29C 67 / 0092 ; B33Y 10 / 00See application file for complete search history .( 57 ) ABSTRACTA method for instructing a 3D printing system that includesa 3D printer provided with a printing coordinate system toprint at least one first object onto an existing second objectcomprises providing or receiving at least one image representing at least a part of the existing second object , determining or receiving an alignment between at least part of theat least one first object and at least part of the existing secondobject , determining a pose of the existing second objectrelative to the printing coordinate system according to the atleast one image , and providing the 3D printing system withthe pose and the alignment for the 3D printer to print at leastpart of the at least one first object onto the existing secondobject according to the pose and the alignment .( 56 ) References CitedU . S . PATENT DOCUMENTS7 , 023 , 536 B2 4 / 2006 Zhang et al .7 , 038 , 846 B2 5 / 2006 Mandella7 , 088 , 440 B28 / 2006 Buermann et al .7 , 110 , 100 B2 9 / 2006 Buermann et al . 20 Claims , 8 Drawing Sheets1A01 1A05 1A04- -j ac WAK RwwwwwwwwwwwwwwwwwwwASMUSWW999 wwwww1A081A061A07Wwwwwwwwwwww wwwwwwwwww1A02 1A03US 9 , 776 , 364 B2Page 2( 56 ) References CitedU . S . PATENT DOCUMENTS8 , 243 , 334 B2 8 / 2012 Abeloe2005 / 0168437 A1 8 / 2005 Carl et al .2010 / 0092079 Al 4 / 2010 Aller2011 / 0087350 A1 4 / 2011 Fogel et al .2011 / 0227915 AL 9 / 2011 Mandella et al .2012 / 0038549 A1 2 / 2012 Mandella et al .2012 / 0210255 A1 8 / 2012 Ooi2012 / 0236031 AL 9 / 2012 Haddick2012 / 0281013 Al 11 / 2012 Mahdavi2013 / 0194418 Al 8 / 2013 Gonzalez - Banos et al .2013 / 0206830 A1 8 / 2013 Kugel2013 / 0215116 AL 8 / 2013 Siddique2013 / 0329243 Al 12 / 2013 Pettis2014 / 0022281 A11 / 2014 Georgeson2014 / 0039663 A1 * 2 / 2014 Boyer . . . . . . . . . . . . . B29C67 / 0051700 / 1182014 / 0074274 A1 3 / 2014 Douglas2014 / 0210947 A1 * 7 / 2014 Finn . . GO1C 15 / 002348 / 462015 / 0093283 A1 * 4 / 2015 Miller . . . . . . . . . . . . . . . . . A61F 2 / 3859419 / 55Alexandre Gillet , Michel Sanner , Daniel Stoffler , Arthur Olson ,“ Augmented Reality with Tangible Auto - Fabricated Models forMolecular Biology Applications , ” 2004 , IEEE Visualization , pp .235 - 241 .Alexandre Gillet , Michel Sanner , Daniel Stoffler , Arthur Olson ,“ Tangible Interfaces for Structural Molecular Biology , ” 2005 ,Structure , 13 : 483 - 491 .Anna Hilsmann , Peter Eisert , “ Tracking and Retexturing Cloth forReal - Time Virtual Clothing Applications , ” 2009 , Proceedings of the4th International Conference on Computer Vision / Computer Graphics Collaboration Techniques , MIRAGE ' 09 , pp . 94 - 105 .J . C . Verlinden , A . de Smit , A . W . J . Peeters , M . H . van Gelderen ,“ Development of a Flexible Augmented Prototyping System , ”2003 , Journal of WSCG , 22 ( 1 ) : 1 - 8 , ISSN : 1213 - 6972 .Jouke Verlinden , Imre Horvath , Edwin Edelenbox , “ Treatise ofTechnologies for Interactive Augmented Prototyping , ” 2006 , Proceedings of the TMCE 2006 , pp . 1 - 14 .Siltanen , Sanni , “ Theory and applications of marker - based augmented reality , ” Espoo 2012 , VTT Science 3 , http : / / www . vtt . fi / inf /pdf / science / 2012 / S3 . pdf .Stewart Von Itzstein , Bruce H . Thomas , Ross T . Smith , SandyWalker , “ Using Spatial Augment Reality for Appliance Design , "2011 , IEEE Conference on Pervasive Computing and Communications Workshops ( PERCOM Workshops ) , pp . 316 - 318 .OTHER PUBLICATIONSAndreas Kolb , Erhardt Barth , Reinhard Koch , Rasmus Larsen :Time - of - Flight Sensors in Computer Graphics . Eurographics 2009 . * cited by examinerV31T?US 9 , 776 , 364 B2EOVDLOVT??TYPY f?-?sir?s?:=?r???.:???????+-????? ???SET?'*SE?FT?F?FRN?TE???? ??*“*?????*:????*?1?*.5:?~??*??????3??? ? ???e?????? 4?=???* -: * ? ??*F*??FF?F* ***A*+=a=rt4??*?4A*?44A444????*AAA**A?*???????(44T4:Y51* * . %* 4 *****PF*:gaynaypa54r5a971-2?*?F4?*:?FPS?E?????????*?Y?*?15-:?}???????17?1?-:;?3?;/ \ | \?)*-;?\};}????*:?????*:?|?*-:???*:;??*:;???1? 5?*-4?*-:???*?*?*?*=?????F4%*+-4%*???FAP?)AP??7% 4 , A ?A?-?r?a?r** ?????P*:*PYrTA*?AA*?*??*?*???*????** ?l e r ",e"*-?AF\"*-\ffff*-?3**-** ::* *r*rrrr* -r***r;Sr4* --.?,*??*?*?*****%%* 4=========!*****?*???**?* fr?:4:- ***?* ? , -+ : ?? - * :?,-=??????--? **-*:- -* \ \ -- -* *?-??????*-? *?**:?:-* - : 4?:? ?>>?:??s*:?crir?14::-?+ :- :*f?? >- :* ? * . 4 A -;: fters *--*"r= " *" ,** ,ira*= -%-4LAs-SF?2P5r?0er?tr?1?Tr'?|rFEartre1?ehFrrreFr ah?*?*?ray s*?*=:???rr r?*Y ?+F*?F???*. *? Arr2A|neMakeAdSGA?A a,3SMenriandasilancienaRso mnaageesigneransANhank?MOAM6Asonistr om*:AAMrehosh soresigninationstagradidashakiAromokog n*a*=rePer F.------" 1*4444S44??J*?J*:A*******,F*P*F*-Y* 4 ??**- *}}} ??????? : *:* :;;Sheet 1 of 8- ??????????????????????????. .? 1?????????????????????????? ??????? **PT*-RAY d?*1e?v1?e4lA *A**?*????* ;," ;* ??er% s"%A%AA%A??r3.ar1r1 * , A r . ?;1*: ****T*** :**rite *? ??*4?*?* ; : ***~*::::|" |\fff*FF*:;?rFFrF* -:*=>?*=???????*+->?Cde?*:;=???*???*?5*:?????4??????'.?tFM*./1????FA?F?P?F???F? ??*?J?*-?\Jr1?*.AJd??4e??r?4??V??eP ?r*??*.a*.?|r?rr?r???????? ?* : * : * '*4*-4?1? **-1*-.1=Tr1-*R"*=??*1?t?? , ,:?-: -+ * ??N?C3E? ? * : .43,9:6Rv\E4N*=?E4NAH4AN4AAA4AP2pKrrAeWeNasvEep?So?I?n?G s?N ?o-?ryF4i',-;4A.;=Lrl4na4rrF , 4 * ?:S???*-?f-1??!*-:??4??4???? ????!-;?F????"*?*??*,?|?*:?????????? ?P\h?rfee\A+-Aftfe":?\trrrrrrrryrr*-*-*-L?F45*4:????4????- **%**-;}??*:???c.???o?ama??d14?!)*rr4?rry4rr*:rr4irrr:*:--?*= ?- % E ,* 1**-:*:=? ?? . A ?. * ?; *?- *??*4*-15?1.15? ; :? ?*????????? ????!LOVI-\ ********? ?. *****?????????????????????????????????????????????????????????????????????????????????????? ? ????*-????-- *- :?+:????r?e ?T-?E??trip Aer? ?????????????????????? ? !! ??r "!90VL???r:?e&:r* =?5?5ty= *R-:;et?==????????????*-?*=?4?,4;??4??4??. : * ;: *: ?*-:;?^?S'*:;>????i??= * r* - - * =A:3:rem?2&-:;?*+:?\?1?1??i*i|i*4-:?AL4l+-:?111-1-1- ? F* : ? :* :F + :- :*?|°-|-|:*.5=?*:;=>??y?O?S*-:?P*-ST3?EP:**s*??eo*-:;?frq?en*:=??*f*=??f???f??f?? f? ?%\?5?"*/:;=????*???4?????? ? ????:;?f%:??*=\sf*f??f?f?ff?*=??*???????A?:AA?A??????rm19A%ArFrkrI5ArArAr?"%,-;?FY?*???444" * \*A **P?*?a?r?e?????!%'-;?PmFr!?e?rrrr"*AF?"*4:?*?F???F*,-????F? ?*4*=4?- ? !?????????FT-A???*?N?rM*?N??Ni*??P??f??M?? f ?S?y*?*?|?*,-:?|**,?*-?| ? |?rL*,1*PP\P* \ +Oct . 3 , 2017?F??????? :?:?: * + . ???i?s::: ??4%4***+ :??????????????????????????????i-?vvre*????1-14 A:=Lrr rM.eplAistr?rr??*?frks*?????????******FF\Y\\*************? ****80VT**???* :? *r*rrrrr1:;?1;* : ?*e*rrer*l4*-:?rrd4774 ' ? * ::??:::::*? **??f = -= :- *:- ::-::* :* *- :;+ - *-:***** = ?8?-989898989?286889389989089869808693908a9ug?0?w??????????sw.ocieteofwthesers???? **???????rwaehnheeurnisstiattegeenmeprartieo ns* ?1)?15sasaidores?s?,T*.:?TTTTT?* ***::?*.?* \- 1?1.11??*:?T"a% A???6 ) * * } '= - *??, -. ::::: ;: * -}???*??: ; V :?*.:?F?????FF4?:?FF??: |F*-=rr= * ? } - { :F* ??-??*,.:=?Pl????*:;??????= * 7 :3 : 2 ; |?:?????:????F?1 4 * : PPP, *?* : : *- + 4?4-.:?:4?4: ?:?*? : * ?: ? : ?}- { \ m?-9*-:GGiW , * * ? ; : ?*| ? *: ; ?*:;=???=?F!*,.;={}?:????P??????*+:;?E?*,:;???????????? ???*:??:?????????????:r:rrr??-}*???*5?*-:>?*:?2?*????e"*.??t?c*??*?????*?r?????*y*-;e?F??=?}???*??? ??,*R** ???}A-r r- -+: -? ?- | -?A?T!"?rip*Pr*?Aeryry?F¥FFF3FF?&?t*??** *5 , * - *? :?*??44 -4?51?4e4r*r4r6- 1V:?,??V?Y?? *-*--"-4T-L1F31 r?? * ? v = -4+-4?-????4:??? ??s.<tr*}???*???????4??3?*;>??????:??F?A-FfSF=?T*F??>?F?F? F?f=?irF*. ! = ??*=?*??**?*???- > : ? **: - *-* - ** * ? ---- *¥34?*? f*?re?*-.?ert*??4?V-1??*.:?44?4L44?4454YAf*+-:?f*-:?rVAfs1*.:?4? * : . E r Y?*?*.:*????*? **??V*???*.:?*.|????S??????*.)*4?*???*r*Er* | **-* * -?*.?*.:???44*?4*?F?*.?4*,.4??4?1??3-344SAWASAMAM*AAR?%?%?4A? WA?A WSA?E?%wM4??A?N??XW?????M????A%???M??????M???A???N?AM??ANN??A4??G?A8 ??W??4AA ???S? AA?a?Wng?o? rW?a gEe sU . S . PatentVOUTGOVITOYUF1.iBgUS 9 , 776 , 364 B21B041303NA1B02ismista1A01L2+ 1 . *124.v1.971.v.i..U7,22s-1:tri. ... !* 2* 1Sheet 2 of 8*Swon2X4X*XXXXX**ww...!4.........1 ..SVE13079091iyowcomOct . 3 , 20171–B08hindiU . S . Patent1B05OTTU . S . Patent Oct . 3 , 2017 Sheet 3 of 8 US 9 , 776 , 364 B22A06 2A102A05. .. . . . . . . . .. .. . .ERA # 1 + Vu+ I + YY !$ $ $ 4 * >BOISES> > Av : 33: Sivu 1:: . YY . . . YYY. WAIT * . I 220A0033 : AXYZ> > > # # # #CAS:AN . . . thi :E - Nr . . . Y riS22AA00882A0222AA001 1 2A04F2.iAgF2.iBg2A01 2,A04 24022A03September R X - 1 ? > >. ivA + + YiIN444 > >? ? : * > >: YrXviiini . . .l i . 11 NNY . . YY " -1 : Yht * . * #XCSONYI > > >R " SYYS$ . . issi . 132A052B062A06 2A10U . S . Patent Oct. 3 , 2017 Sheet 4 of 8 US 9 ,7 76 , 364 B2U . S . Patent Oct . 3 , 2017 Sheet 5 of 8 US 9 , 776 , 364 B22A06 20102008 1A01WSIEIE > >enter * 3 . EXPERIEUR 4 X> . LAKIR...A . !G * S 4:4ARA heittoa RE+ 27 ATOSSA F* 3 2. 5 .vt , 3> < P . TO < P2 : . . . s Y - > X N. . . * . . 3 . *. . . .SKSS 1 . 13. CFeABS ' 2 . . . , . 4 . .2 . 2 , . Ties 3 V ! * . * * * ,SE * ** S*3 .2 4 1 8, 1 3 ,. ... S 2TATCOUN SAS SIS33 ' S,4 2A03 82A01 2A02 2A042F.iCgU . S . Patent Oct . 3 , 2017 Sheet 6 of 8 US 9 , 776 , 364 B22A06 2410200920082A03 >- -+2-A022A01 2A04F2.iDg3001eosPta()xbelicjhsateoncicnenedtgrpft3t()aerlihoanDottierevreof olpapbrierjiniranenttscteittetngreootxbnijhsteticeontgU . S . PatentAcilu3oa|caems0qmnaiue0tignsrer2egtae30043003Dcptaoaeatomheresftmreienaerilotteemlhnaatogsieveteeoos(]pxbeitcjiseootincnandtglDclptaoaeaetomeharesftmsrieentaecpioiaoromirnndatningieantegeopst3o()prytishinotDftneeeamrlnoOct . 3 , 2017Desptoaexetiohecsrftsomieinnendgecposiaorbyoirjsndnetitniceantmtge3006etIxihstfieng osibecjeoscndt pwariitnhtiinng 3toahrDfeea printer3005Sheet 7 of 8yesdaPp-aelrtioegrrvnmmiieendneetdbflpotaoeeiathnarwftreseettneolpataoxbeiajhnsateftrsicdentttgosbecjeocndtPflpotaoeirahnairrftnsett eoloptaoxbeanihjsafterttsiecotnttg posut3rbesicjhineoDtncneegdtr30083007US 9 , 776 , 364 B2F.3ig500250035001atentcpPaorroiorndvtiiniadntege pst3oryihsnDftteeemrdaPbp-aelertiotegrrvwnmmeiieendeneentd oflpaotaobeiajhnarerftscdettteoslptaoxbeeaicjhsarfteotsicnetntdtg...opPaoorrisogivfnitiindaoeln oflotaibeijhnarentscett cptoroirhnditnieantge system.Oct . 3 , 20175004oDppsao()arelopiatseacenniterttfamiiteidaionolnetncepostiorxbeyoircjshnsdteotinniceneantdmtge5005apDstatotaclipaacrascorhptergefodmileieeaantlygteostxbeihcjseotiecnndtgSheet 8 of 85006aeosPlptaotcxbeelcaiocjhsareorfottdcsiicnetnnetdtggdtatiasrhprlegaeyeaetdF.4igUS 9 , 776 , 364 B2US 9 , 776 , 364 B2METHOD FOR INSTRUCTING A 3D lower base portion . This method is not related to printing aPRINTING SYSTEM COMPRISING A 3D physical object by a 3D printer .PRINTER AND 3D PRINTING SYSTEMSUMMARY OF THE INVENTIONBACKGROUND OF THE INVENTIONThe inventors found that there may exist a need for further1 . Technical Field applications of a 3D printer , such as extending an existingThe present disclosure is related to a method for instruct real object through printing additional objects onto a surfaceing a 3D printing system comprising a 3D printer and to a of the existing object by using a 3D printer . One challenge3D printing system . The present disclosure is further related 10 in such applications may be where to place the existingto a method for instructing a device communicating with a object or how to adjust one or more print heads of the printer 3D printing system comprising a 3D printer. such that the additional objects will be printed onto a desired 2 . Background Information area of the surface of the existing object in order to build a composed object satisfying a pre - determined alignmentCommonly known 3D printers that could perform 3D 15 between the additional objects and the existing obiect .printing processes to print a real object from an input of a NNoonnee ooff tthhee pprriioorr art as mentioned above discloses anyvirtual model are presently available to consumers . As solution to solve the problem of using a 3D printer to printknown in the art , additive manufacturing based 3D printing at least one object onto a desired surface area of an existingis a promising and emerging technology to print or create a object or a part of the existing object in order to build a3D or 2D real ( i . e . physical and tangible ) object of any 20 composed object satisfying a pre - determined alignmentshape . As known in the art , additive manufacturing or 3D between the at least one object and the existing object .printing is a process of making a three - dimensional solid Therefore , it is an object of the invention to provide aobject of virtually any shape from a virtual model . 3D method for instructing a 3D printing system comprising aprinting is achieved using an additive process , where suc - 3D printer which is adapted to print at least one object ontocessive layers of material are laid down in different shapes . 25 a desired surface area of an existing object or a part of theFor example , to perform a print , the 3D printer reads the existing object in order to build a composed object satisfyingdesign from a file and lays down successive layers of liquid , a pre - determined alignment between the at least one objectpowder , paper or sheet material to build the model from a to be printed and the existing object . A further object of theseries of cross sections . These layers , which correspond to invention is to provide a corresponding 3D printing system .the virtual cross sections from the virtual model, are joinedà 3300 In a first aspect, there is disclosed a method for instructingor automatically fused to create the final shape . The primary a 3D printing system comprising a 3D printer provided withadvantage of this technique is its ability to create almost any a printing coordinate system to print at least one first object three - dimensional shape or geometric feature . onto an existing second object, the method comprising : The virtual model represents the geometrical shape of the providing or receiving at least one image representing at real object to be built or printed . The virtual model couldW bCe 35 least a part of the existing second object, determining or any digital model or data that describes geometrical shape roencee ifvirisnt go baine catl aingdn maetn lte absett pwaerte no fa tth el eeaxsits tpianrgt sofe ctohne d aotb jleecastt .property , such as a computer - aided design ( CAD ) model or determining a pose of the existing second object relative toan animation model . The printed real object is tangible . The the printing coordinate system according to the at least oneobject or the part of the object may have a void or hollow in 40 image , and providing the 3D printing system with the poseit , such as has a vase . The object or the part of the object may and the alignment for the 3D printer to print at least part ofbe rigid or resilient , for example . the at least one first object onto the existing second object3D printers are commonly based on additive manufactur - according to the pose and the alignment .ing that creates successive layers in order to fabricate 3D According to another aspect , there is provided a 3Dreal objects . Each lay could be created according to a 45 printing system adapted for printing at least one first objecthorizontal cross - section of a model of a real object to be onto an existing second object comprising : a 3D printerprinted . 3D printers are typically used to create new physical provided with a printing coordinate system and a processingobjects that do not exist before . device adapted to receive at least one image representing atIn US 2011 / 0087350 A1 , there is provided a method and least a part of the existing second object . The processingsystem enabling the transform of possibly corrupted and 50 device is further adapted to determine an alignment betweeninconsistent virtual models into valid printable virtual mod at least part of the at least one first object and at least partels to be used for 3D printing devices . of the existing second object , and further adapted to deterU . S . Pat . No . 8 , 243 , 334 A generates a 3D virtual model mine a pose of the existing second object relative to thefor the use in 3D printing by automatically delineating 55 image . The 3D printer is adapted to print at least part of theprinting coordinate system according to the at least oneobject of interest in images and selecting a 3D wire - frame at least one first object onto the existing second objectmodel of an object if interest as the virtual model . The 3D according to the pose and the alignment .wire - frame model may be automatically calculated from According to another aspect , there is disclosed a methodstereoscopic set of images . for instructing a device communicating with a 3D printingU . S . Pat . No . 7 , 343 , 216 A proposes a method of assem - 60 system comprising a 3D printer provided with a printingbling two real physical objects to have a final physical coordinate system and adapted for printing at least one firstobject . The method discloses an architectural site model object onto an existing second object , the method comprisfacilitating repeated placement and removal of foliage to the ing providing or receiving an alignment between the at leastmodel . The site model is constructed as an upper shell one first object and at least part of the existing second object ,portion and a lower base portion , while the model foliage is 65 providing or receiving an original position of the at least oneattached to the shell portion . The upper shell portion of the first object in the printing coordinate system , the originalsite model is configured for removable attachment to the position being a position at which at least part of the at leastUS 9 , 776 , 364 B2one first object is to be printed onto the existing second one first object onto an existing second object comprisingobject , determining a spatial placement of the existing placing the existing second object or a part of the existingsecond object in the printing coordinate system according to second object , capturing at least one image using at least onethe alignment and the original position of the at least one camera , the at least one image containing a first part of thefirst object , and instructing the device to display a target area 5 3D printer and at least part of the existing second object , andaccording to the determined spatial placement of the existing the first part of the 3D printer having a known spatialsecond object for placing the existing second object accord relationship relative to the printing coordinate system of theing to at least part of the displayed target area . 3D printer , providing an alignment between at least part ofAccording to another aspect , there is provided a 3D the at least one object and at least part of the existing object ,printing system adapted for printing at least one first object 10 determining a pose of the existing object relative to theonto an existing second object comprising a 3D printer printing coordinate system according to the at least oneprovided with a printing coordinate system , a processing image , and providing the 3D printing system with the posedevice adapted to determine or receive a spatial placement and the alignment for the 3D printer to print at least part ofof the existing second object in the printing coordinate the at least one first object onto at least part of the existingsystem , wherein the spatial placement of the existing second 15 second object according to the pose and the alignment .object is dependent upon an alignment between the at least According to a further aspect , particularly useful when aone first object and at least part of the existing second object , camera is attached to the 3D printer , there is provided aand upon an original position of the at least one first object method for instructing a 3D printing system comprising ain the printing coordinate system , the original position being 3D printer provided with a printing coordinate system toa position at which at least part of the at least one first object 20 print at least one first object onto an existing second objectis to be printed onto the existing second object , a device comprising providing a pose of at least one camera relativeadapted for communicating with the processing device and to the printing coordinate system of the 3D printer , placingadapted to display a target area according to the spatial the existing second object or a part of the existing secondplacement of the existing second object , and the 3D printer object , capturing at least one image using the at least oneadapted to print at least part of the at least one first object 25 camera , wherein the at least one image represents at leastonto the existing second object when the second object is part of the existing second object , providing an alignmentplaced according to at least part of the displayed target area . between at least part of the at least one first object and atAccording to another aspect , there is provided a computer least part of the existing second object , determining a poseprogram product comprising software code sections config - of the existing second object relative to the printing coorured for performing the methods as described herein . 30 dinate system according to the at least one image , andThus , in order to enable a 3D printer to print at least one providing the 3D printing system with the pose and thefirst object onto the desired surface area of an existing alignment for the 3D printer to print at least part of the atsecond object , the inventors found that one possible solution least one first object onto at least part of the existing secondis to let the 3D printer know where the existing second object according to the pose and the alignment . In thisobject is located relative to the 3D printer in three dimen - 35 embodiment , there is no need to include a part of the 3Dsional space . For this aim , the present invention proposes , in printer into the image .a first aspect , to determine a pose between the 3D printer and According to a further aspect , there is provided a methodthe existing second object using one or more camera images for instructing a 3D printing system comprising a 3D printerand , in a second aspect , to instruct a device to illuminate a provided with a printing coordinate system to print at leastplace where the existing second object has to be positioned 40 one first object onto an existing second object comprisingaccording to the pre - determined alignment . providing a virtual model or an image of the existing secondOne application which could benefit from the present object or a part of the existing second object , providing aninvention is to resume a 3D printing process of printing an alignment between at least part of the at least one first objectobject . When a printing process of printing an object from an and at least part of the existing second object , and instructinginput of a virtual model using a 3D printer is interrupted and 45 a device , such as a display or projecting device , to displaythe printed part of the object is moved away from the printer , a target area according to the alignment for placing theresuming the printing process requires printing the remain existing second object according to at least part of theing part of the object onto a desired area of the already displayed target area . The existing second object may thenprinted part in order to build the complete object satisfying be placed according to at least part of the target area .the input of the virtual model . In this example , the printed 50 In one embodiment , the 3D printer is an additive manupart of the object is an existing second object , the remaining facturing based machine to make ( or print ) an object from apart is one or more additional objects to be printed ( the at virtual model of the object through a sequential layeringleast one first object ) , and the virtual model defines a process . The shape of the printed model is determined atpre - determined alignment between the printed part and the least partially according to the virtual model .remaining part . 55 A virtual model of an object describes a geometrical shapeAs used herein , the term " existing object " shall not be property of the object . The virtual model could be 3D or 2D .understood as being an intermediate object or product with The virtual model could also be an orthogonal or perspectivea certain amount of layers in a continuous 3D printing 2D projection from a 3D model of the object . The perspecprocess in which one layer after the other is deposited upon tive 2D projection may also be an image of the objectto form an object or product . Rather , “ existing object ” shall 60 captured by a camera . The virtual model may further containbe understood as being , e . g . , an object which , as a whole , is texture information , e . g . textures or colors of surfaces of thenewly placed in the 3D printer for printing something object .additional onto it so that the position of the object has to benewly determined . BRIEF DESCRIPTION OF THE DRAWINGSAccording to a further aspect , there is provided a method 65for instructing a 3D printing system comprising a 3D printer FIG . 1A shows , as a possible embodiment of the invenprovided with a printing coordinate system to print at least tion , a 2D blueprint of a room planning .US 9 , 776 , 364 B2FIG . 1B shows , as a possible embodiment of the inven The at least one camera used for the purposes of thetion , objects such as physical models of furniture printed by invention could also be a structured light scanning device ,a 3D printer on the 2D blueprint shown in FIG . 1A . which could capture the depth and surface information ofFIG . 2A shows a 3D printing system adapted for printing real objects in a real world , for example using projected lightat least one first object onto an existing second object 5 patterns and a camera system . The at least one image may beaccording to an embodiment of the invention , wherein the a color image in the RGB format or any other color format ,existing second object is a cup placed on a printing platform or a grayscale image . The at least one image may also furtherof a 3D printer . have depth data .FIG . 2B shows a 3D printing system according to another The printing coordinate system of the 3D printer definesembodiment of the invention , in which a handle is printed by 10 a coordinate system for a 3D printing process of the 3Dthe 3D printer onto an existing cup . printer for printing an object . Components related to the 3DFIG . 2C shows a 3D printing system according to another printing process , e . g . a print head or a part of it , have knownembodiment of the invention , in which a 2D paper is placed positions in the printing coordinate system . A used printingon a printing platform of a 3D printer . platform or a part of the printing platform may also have aFIG . 2D shows a 3D printing system according to another 15 known position in the printing coordinate system . Theembodiment of the invention , in which an area is illuminated position of the printed first object at its original position ( i . e . ,visually on a printing platform . no movements after the corresponding 3D printing processFIG . 3 shows a flowchart of a method of printing at least of printing the first object is complete ) is known in theone first object onto an existing second object using a 3D printing coordinate system .printer according to an embodiment of the invention . 20 The first part of the 3D printer is a visual or visible part ,FIG . 4 shows a flowchart of a method of printing at least which may be directly connected or separated from the 3Done first object onto an existing second object using a 3D printer .printer according to another embodiment of the invention . For example , coordinate system 2A10 is a printing coordinate system of 3D printer 2A01 , in which the positions ofDETAILED DESCRIPTION OF THE 25 printer head 2A03 , printing platform 2A02 , and first partINVENTION ( designated by reference 2A04 ) of the 3D printer are known .A “ pose ” as used herein shall be understood as is comFIGS . 2A to 2D show a respective 3D printing system monly known in the art . A pose has up to six degrees ofrespectively adapted for printing at least one first object onto freedom ( DOF ) which describe the position and orientationan existing second object according to various embodiments 30 in 3D space . In 3D space , the position is defined by threeof the invention . One embodiment of a 3D printer used for translation parameters , e . g . displacements along threethe purposes of the present invention may be a 3D printer orthogonal axes , and the orientation may be defined by three2A01 comprising a print head 2A03 and a printing platform Euler angle parameters . The orientation may also be repre2A02 . The 3D printer may move the print head and / or the sented in other math formulas , e . g . axis angle and quaterprinting platform to print an object . Material and / or binding 35 nions . It is always possible to convert the math representamaterial is deposited from the print head on the printing tions of the rotation to each other . A specific pose in theplatform or a printed part of an object until a complete object present invention could be determined by at least one of thehas been printed or made . Such process is commonly known inherent six parameters of the position and orientation inby the person skilled in the art and shall not be described in three dimensional spaces .more detail for reasons of brevity . 40 The alignment between at least part of the at least one firstIn terms of the present invention , the existing second object and at least part of the existing second object as usedobject or the at least one first object could be , in principle , herein may be a pose of the at least part of the at least oneany type of real object . The real object is physical and first object relative to the at least part of the existing secondtangible . The real object or a part of the real object may have object . The alignment may also be a transformation betweena void or hollow in it , such as has a vase . The physical object 45 at least part of the at least one first object and at least partor the part of the physical object may be rigid or resilient of the existing second object . The alignment may be manuFor example , real cup 2A05 is an existing second object , ally determined . The alignment could also be determinedwhich has been previously manufactured by any apparatus , automatically .and is ( newly ) placed in the 3D printer , and handle 2B06 is in the following embodiments of the invention will bean at least one first object to be printed onto a surface of real 50 further described in more detail .cup 2A05 by printer 2A01 . The printing area of the 3D In order to correctly make or print an object using a 3Dprinter is an area where the print head could reach to deposit printer , printing process related components of the 3Dmaterial or a binding material . printer , e . g . print heads and printing platforms , have aThe proposed invention can be generalized to be used known spatial relationship between each other . Thus , thewith any device providing images of real objects . It is not 55 components of the 3D printer could be defined in an arbirestricted to cameras providing color images in the so - called trary common coordinate system called printing coordinateRGB ( red - green - blue ) format . It can also be applied to any system . A pose of the object to be printed of its originalother color format and also to monochrome images , for location ( i . e . no movements occur relative to the 3D printerexample to cameras providing images in gray scale format . after the corresponding 3D printing process is complete )The camera may further provide an image with depth data . 60 relative to the printing coordinate system is known .The depth data does not need to be provided in the same In practice , there may be a need that an existing object beresolution as the ( color / grayscale ) image . A camera provid - extended by adding additional objects onto it in order toing an image with depth data is often called RGB - D camera . build a composed object . In such case , there is a need to printA useful RGB - D camera system could be a time of flight at least one first object onto an existing second object to( TOF ) camera system . Kolb et al . in reference [ 7 ] give an 65 build a composed object using a 3D printer .overview on state of the art on time - of - flight camera sensors For example , a 3D printer could print a handle onto anand applications . existing cup to build a composed object of the cup with theUS 9 , 776 , 364 B2handle . The handle may have to be printed at a desired place The existing second object or a part of the existing secondof the cup satisfying a design . The design defines a spatial object should be placed within a printing space of the 3Dalignment between the handle and the cup in the final printer such that the 3D printer could print at least one firstcomposed object . The spatial alignment may only specify object onto the existing second object . For example , a printthat the handle is attached to an outside surface of a side ( i . e . 5 head of the 3D printer would be able to deposit materials ornot a bottom and top ) of the cup . In this case , the handle binding materials onto the existing second object or a part ofcould be attached to any area of the outside surface , but not the existing second object . The 3D printer could be equippedto a specific location . The spatial alignment may specify that with more than one print heads .the handle has to be attached to a specific location of the FIG . 3 shows a flowchart of a method according to anoutside surface of the cup in a specific pose . In this way , an embodiment of the present invention .alignment between at least part of the at least one first object An existing second object is placed relative to a 3D printer( here : handle ) and at least part of the existing second object for the 3D printer printing at least one first object onto the( here : cup ) may be determined . existing second object ( step 3001 ) . Then , at least one imageThe alignment may be determined by the 3D printing is captured by at least one camera ( step 3002 ) . The capturedsystem or by a device which is separate from the 3D printing at least one image may contain a first part of the 3D printer ,system , e . g . a mobile phone or any other type of processing at least part of the existing second object , or both . For furtherdevice , such as a personal computer or tablet computer . If details , it is referred to embodiments described below .the alignment is determined by the separate device , the Afterwards , optionally , a camera pose of the camera capseparate device could send the alignment to the 3D printing 20 turing the at least one image relative to the existing secondsystem via a cable , wirelessly or via a computer network . object is determined ( step 3003 ) and a camera pose of theIn order to enable a 3D printer to print at least one first camera capturing the at least one image in the printingobject onto a desired surface area of an existing second coordinate system of the 3D printer is determined ( stepobject or a part of the existing second object , one possible 3004 ) . Then , a pose of the existing second object in thesolution is to let the 3D printer know where the existing 25 printing coordinate system is determined ( step 3005 ) . Havsecond object locates relative to a printing coordinate system ing the determined pose of the existing second object , it isof the 3D printer . For this , the present invention proposes to possible to check if the existing second object is within adetermine a pose of the existing second object in the printing printing area of the 3D printer ( step 3006 ) . If the existingcoordinate system of the 3D printer using one or more second object is not within the printing area , then theimages . The one or more images may be captured by a 30 existing second object should be moved relative to the 3Dcamera or multiple cameras . The one or multiple cameras printer ( step 3001 ) , and the process beginning with stepmay be held by users or rigidly attached to the 3D printer or 3001 starts again . It may be necessary to provide a presomewhere else . The one or multiple cameras or a part of the determined alignment between at least part of the at least onecameras may be a component of the 3D printing system or first object and at least part of the existing second objectcoupled to the 3D printing system via cables or wirelessly , 35 ( step 3007 ) . Finally , the 3D printer prints at least part of thee . g . by Bluetooth technology . at least one first object onto at least part of the existingThe one or multiple cameras or a part of the cameras may second object according to the alignment and the pose of thebe a component of a device which is separate from the 3D existing object ( step 3008 ) .printing system , e . g . of a mobile phone or any other type of The way of defining or determining the alignmentprocessing device , such as a personal computer or tablet 40 between at least part of the at least one first object and atcomputer . In this embodiment , the separate device could least part of the existing second object may be manually orsend the captured images to the 3D printing system via a automatically . A user may manually define the alignmentcable , wirelessly , or via a computer network , and then the between the at least part of the at least one first object and3D printing system determines the pose of the existing the at least part of the existing second object . For this , thesecond object in the printing coordinate system using the 45 user , e . g . , could manipulate a virtual model of the at leastcaptured images . one first object and a virtual model of the existing secondIt is also possible to determine the pose of the existing object in order to adjust their spatial relationship with visualsecond object in the printing coordinate system using the feedback in a 3D animation software . The virtual model ofcaptured images by means of the separate device , and then the at least one first object is normally available , as the 3Dthe separate device sends the pose of the existing second 50 printer needs the virtual model to print the at least one firstobject to the 3D printing system . object .As soon as the pose and the alignment are provided to the The virtual model of the existing second object may be3D printing system , the 3D printer is capable to print the at known or computed from one or more images , e . g . taken byleast one first object onto the existing second object accord - a camera . The virtual model may be a perspective projectioning to the pose and the alignment . The 3D printing system 55 of the existing second object or a part of the existing secondmay be instructed accordingly , e . g . by communicating object , for example obtained from an image captured by aappropriately with the separate device , e . g . mobile phone . camera . The virtual model may describe a 3D shape of theAccording to an embodiment , the printing process will only existing second object . The 3D shape could be computedstart after the pose and the alignment are available in the 3D from two images of the existing second object captured byprinting system . For example , it will start pursuant to 60 cameras . The 3D shape may be computed based on asending the data and , e . g . , a command given by a user , e . g . fundamental matrix relating corresponding points in the twoby pressing a button . images and a triangulation method . The 3D shape may alsoThe images may be color images in the RGB format or be obtained from an image with depth data .any other color format , or grayscale images . The images An aspect of the present invention is to enable the 3Dmay also further have depth data . The depth data does not 65 printer to print the at least one first object onto a desiredneed to be provided in the same resolution as the ( color place of the existing second object by determining a pose P .grayscale ) image . of the existing second object in the printing coordinateUS 9 , 776 , 364 B2system of the 3D printer using at least one image , e . g . could capture an image of a printed object printed by the 3Dcaptured by at least one camera . printer . A camera pose relative to the printed object can beThe pose P , may be estimated by using an image , e . g . a determined according to the captured image and a virtualfirst image captured by a camera . In one embodiment , pose model of the printed object . As the printed object has aP could be determined from a camera pose Pay of the first 5 known position in the printing coordinate system , the poseimage in the printing coordinate system and camera pose could be computed . Calibration of the pose of the fixedPcle of the first image relative to the existing second object . camera may also be realized by using the camera to captureCamera pose Pen and / or camera pose Pcle can be deter - an image of one or more visual markers ( fiducials ) at knownmined by using various computer vision methods based on positions relative to the 3D printer ( e . g . in the printingthe first image . In another embodiment , pose P . may be 10 coordinate system ) . Camera pose Pelp of the first image indetermined from the first image without explicitly comput - the printing coordinate system could be directly obtained , ifing camera pose Pelp and / or camera pose Pcle the first image is captured by the camera fixed to the 3DIt may be necessary to determine camera pose Pelp of the printer .first image in the printing coordinate system . The camera may be fixed to an end effector of a mechaniWhen the first image contains a first part of the 3D printer , 15 cal arm . A base of the arm is fixed to the position known incamera pose Pacould be computed based on the first the printing coordinate system . The arm would provide theimage . The first part of the 3D printer has a spatial relation - position of the end effector to the base .ship ( i . e . pose , denoted by Part ) relative to the printing In another example , a tracking system , e . g . optical trackcoordinate system . Pfirst may be pre - known or estimated . ing or magnetic tracking system , is used to compute posesThe first part of the 3D printer may also have a known virtual 20 of the camera in the printing coordinate system . This maymodel or a known geometrical size . Various computer vision require attaching some fiducials to the camera and the 3Dalgorithms could be employed to compute camera pose Pau printer and first compute poses of the camera and the 3Dof the first image relative to the first part of the 3D printer printer in a common tracking coordinate system of theaccording to the first image . For example , having known tracking system .intrinsic parameters of the camera , at least three correspon - 25 It might be necessary to determine camera pose Pale of thedences between three image points and three real points of first image relative to the existing object .the first part of the 3D printer are sufficient to compute pose When a virtual model of the existing second object or aPell for 6 DOF . Then camera pose Pclp could be determined part of the existing second object is known , a camera poseaccording to pose Pirs and pose P . 11 . relative to the existing second object could be computedThe first part of the 3D printer may be attached to the 3D 30 from an image containing the existing second object or theprinter during manufacturing of the 3D printer or afterwards . part of the existing second object . Thus , when the first imageIn this case , pose Pfirst could be known from the mechanical contains the existing second object or a part of the existingdesign or the manufacturing of the 3D printer . The first part second object that has a virtual model , pose Pcle can beof the 3D printer could also be attached to an arbitrary place realized based on feature ( e . g . points or edges ) corresponrelative to the 3D printer after the 3D printer is manufac - 35 dences between the model and the first image or matchingtured . In this situation , pose Pfirst could be estimated manu - 2D projection of the virtual model to the image . If the firstally using measurement gauges , e . g . rulers , or using com - image has associated depth data , pose Pale could also beputer vision based calibrations . A computer vision based determined by matching a surface data set from the modelcalibration for computing pose Pfirst may comprise printing with another surface data set from the first image .an object from a virtual model by the 3D printer , and using 40 It is also possible to rigidly attach a visual marker at aa camera to capture an image of the first part of the 3D fixed known location relative to the existing second object .printer and at least part of the printed object . Camera poses Determining camera pose Pale could be realized by deterrelative to the first part of the 3D printer and relative to the mining the camera pose of the first image relative to theprinted object could be computed respectively based on visual marker . For this , the first image has to contain thefeature correspondences or their virtual models . As the 45 visual marker .printed object could have a known position in the printing The first image may be captured by a camera that is fixedcoordinate system , pose Por is estimated according to the at a position known with respect to the existing secondcamera pose relative to the first part of the 3D printer and the object . In that case , pose Pcle could be obtained from thecamera pose relative to the printed object . known camera position .When a virtual model of the 3D printer is known , pose 50 It is also possible to determine pose P . from the firstPelp can be realized based on feature correspondences image without explicitly computing camera pose Pelp andbetween the virtual model and the first image or matching camera pose Pale . Pose P , may be estimated from a trans2D projection of the virtual model to the image . If the first lation and a rotation between the first part of the 3D printerimage has depth data , pose Pelo could also be determined by and the existing second object in a 2D image coordinatematching a surface data set from the model and another 55 system of the first image . For example , an existing secondsurface data set of the 3D printer from the first image . object , such as 2D paper 1A01 , is placed on a planar printingThe camera pose ( Pclp ) of the first image in the printing platform 2A02 of 3D printer 2A01 ( see FIG . 2C ) . The planarcoordinate system of the 3D printer could also be deter - printing platform has a known position in the printingmined if the camera is fixed at a position known in the coordinate system 2A10 . In this case , determining pose P .printing coordinate system . For example , camera 2C08 is 60 only needs to compute an on - plane rotation and translationfixed to 3D printer 2A01 near to print head 2A03 ( see FIG . of the existing second object relative to the printing plat2C ) . The camera could also be mounted to a movable part of form . Computing the on - plane rotation and translation couldthe 3D printer , in which the movable part could move to a be based on a translation and rotation between the first partknown position in the printing coordinate system of the 3D of the 3D printer and the existing second object in the imageprinter . It is possible to calibrate a pose of the camera 2C08 65 coordinate system of the first image . This may be realizedfixed to a part of the 3D printer in the printing coordinate based on pixel locations of one or more parts of the existingsystem 2A10 . In order to calibrate the pose , the fixed camera second object in the first image . The one or more parts areUS 9 , 776 , 364 B212on the same plane level as the plane of the printing platform , printing coordinate system . Thus , pose P . of the existingi . e . the one or more parts have a zero distance to the printing second object in the printing coordinate system is obtained .platform along the normal of the printing platform . The In addition to the components as mentioned above , the 3Dtranslation and rotation in the image coordinate system of printing system according to FIGS . 2A to 2D comprises , inthe first image may have perspective effects , i . e . the image 5 addition to the 3D printer 2A01 , a processing device 2A06plane of the camera capturing the first image is not parallel ( such as a microcomputer of any type , e . g . a mobile phone ,to the plane of the printing platform . Determining the or a tablet computer ) which is coupled and adapted toon - plane rotations and translations requires rectifying the receive at least one image captured by a camera 2A08 ( FIG .first image or knowing a homography for the perspective 2A ) or camera 2C08 ( FIG . 2C ) , with the captured imagetransformation , when the first image has the perspective 10 containing one or more of the objects as mentioned above .effects . For the rectifying and converting pixel measure The processing device 2A06 is adapted to determine an ments to metric measurements , plane parameters ( i. e . nor alignment between at least part of the at least one first object and at least part of the existing second object as described mal and distance to the camera of the first image ) of the above, and is further adapted to determine a pose of the printing platform are needed , see reference [ 4 ] . Tnhee ppllaannee 15 existing second object relative to the printing coordinate parameters can be computed from a planar reference in the system according to the received at least one image . The first image . For example , reference 2A04 on printing plat processing device 2A06 is adapted to communicate with theform 2A02 could be used as a planar reference . Reference 3D printer with , e . g . , its printer head 2A03 accordingly for2A04 has a known geometry and known position relative to sending the information as described herein . It may also3D printer 2A01 or printing coordinate system 2A10 and , 20 control the 3D printer if appropriate in the particular applithus , may serve to designate a first part of the 3D printer . cation .The pose P , may be estimated by using multiple images , For enabling a 3D printing system comprising a 3Dfor example using a first image and a second image captured printer to print at least one first object onto a desired surfaceby cameras . area of an existing second object or a part of the existingIt is also possible to reconstruct a 3D shape of the existing 25 second object according to an alignment between the at leastsecond object or a part of the existing second object from at one first object and the existing second object , anotherleast two images captured by cameras . For the 3D recon - aspect of the invention proposes to instruct a device , such asstruction , the at least two images have to be captured at a projector or a display , e . g . of a mobile device , to illuminatedifferent camera positions when the images have no depth or display a target area indicating where the existing secondinformation . The at least two images may be captured by one 30 object should be positioned in order for the at least one firstcamera or different cameras . The at least two images are a object to be printed onto the existing second object .first image and a second image . The 3D shape may be An original position of an object to be printed by the 3Dreconstructed based on triangulation according to the first printer is defined by a pose relative to a printing coordinateimage and the second image . Triangulation refers to the system of the 3D printer , at which the object to be printed isprocess of determining the position of a feature in 3D space 35 located , without movements having occurred after the corgiven its projections ( image features ) onto two , or more , responding 3D printing process for printing the object hasimages . completed . The original position of the object to be printedFor the triangulation , the camera pose of the first image could be arbitrary within a valid range and is known in theand the camera pose of the second image in one common printing coordinate system . The valid range is defined bycoordinate system is needed . The common coordinate sys - 40 working space of the print heads of the 3D printer .tem could be the printing coordinate system or a coordinate According to the invention , the alignment between the atsystem of the camera of the first image or the second image . least one first object and at least part of the existing secondSeveral different embodiments of determining a camera pose object could determine a spatial placement of the existingof an image in the printing coordinate system are proposed second object in the printing coordinate system ( i . e . aby the present invention . In order to estimate the camera 45 position and orientation of the existing second object in theposes of the first and second images in the printing coordi - printing coordinate system ) according to the original posinate system , the first and second images capture a first part tion of the at least one first object to be printed . The existingand a second part of the 3D printer that have known poses second object may be required to be placed on the printingin the printing coordinate system respectively . The first part platform . In this case , an orthogonal projection of theand the second part may be a same part or two different 50 existing second object at the determined spatial placement toparts . The first and second images may be captured by a the printing platform defines a target area on the printingsame camera or different cameras . If the images are captured platform where the existing second object should be posiby a camera mounted to a movable part of the 3D printer and tioned for printing the at least one first object onto a desiredthe movable part could move to a known position , the surface of the existing second object . The spatial placementcamera pose of the first image and the camera pose of the 55 of the existing second object in the printing coordinatesecond image in one common coordinate system could be system may be determined by the 3D printing system . Fordirectly obtained . The camera capturing the images could this , the alignment and the original position of the at leastalso be mounted to a movable part of a mechanical arm , one first object have to be provided to or determined by thewhich could provide a motion of the movable part . 3D printing system .The reconstructed 3D shape of the existing or the part of 60 An illumination of a target area may be realized bythe existing second object can be used to define the align - embedding light sources , e . g . LED ( light emitting diode ) ,ment between the at least one first object and the existing into the printing platform . The illumination of the area maysecond object . also be realized by using a projector to project a pattern orHaving known camera poses of the first image and the some visual effects . Particularly with using the projector , thesecond image in the printing coordinate system for recon - 65 projected pattern or visual effects may be visible on a surfacestructing the 3D shape of the existing second object , the of the existing second object . The pattern or visual effectsreconstructed 3D shape may be directly related to the could facilitate to adjust the placement of the existingUS 9 , 776 , 364 B213 14second object , e . g . by aligning an edge of the existing existing second object is placed according to at least part ofsecond object with a corresponding edge of the pattern . The the displayed target area 2009 , the 3D printer may print theprojector may be a component of the 3D printing system or at least one first object onto the existing second object .coupled to the 3D printing system via cables or wirelessly , FIG . 4 shows a flowchart of a method of printing at leaste . g . by Bluetooth . It might be necessary to have a known 5 one first object onto an existing second object using a 3Dprojector position in the printing coordinate system in order printer according to another embodiment of the inventionto project the pattern or visual effects onto the area . The illuminating an area indicating where the existing secondprojector could be fixed relative to the printing coordinate object should be positioned . In step 5001 , a printing coorsystem and has known position in the printing coordinate dinate system of the 3D printer is provided , as describedsystem . 10 above . According to step 5002 , an original position of the atAnother way of displaying a target area where the existing least one first object in the printing coordinate system issecond object should be positioned is to highlight or illu - provided . The original position is a position at which at leastminate the area in an image or a live video containing the part of the at least one first object is to be printed onto thearea captured by a camera . Highlighting or illumination existing second object , see for example below description ofcould be realized by overlaying a computer - generated image 15 how the handle to be printed onto the cup is positioned .with the target area in the captured image or live video . In Further , a pre - determined alignment between at least part ofthis case , a camera that provides a live video can support a the at least one first object and at least part of the existinguser placing the existing second object into the area , as the second object is provided , e . g . an alignment between handlelive video provides a real - time visual feedback where the and cup ( step 5003 ) . In the following step 5004 , a spatialexisting second object resides relative to the area . The 20 placement ( position and orientation of the existing secondcamera may be a component of the 3D printing system or object in the printing coordinate system is determined . Then ,coupled to the 3D printing system via cables or wirelessly , in step 5005 , a target area according to the spatial placemente . g . by Bluetooth . It might be necessary to have a known of the existing second object is displayed . In step 5006 , thecamera position in the printing coordinate system in order to existing second object is placed according to at least part ofoverlay the real - time visual feedback onto the image or the 25 the displayed target area , and at least part of the at least onelive video of the camera . The camera could be fixed relative first object may be printed onto the thus placed existingto the printing coordinate system and has a known position second object .in the printing coordinate system . A possible application of printing a first object onto anThe spatial placement of the existing second object in the existing second object using a 3D printer is printing one orprinting coordinate system may be determined by a separate 30 more 3D physical models of an environment onto a 2D mapdevice , e . g . a mobile phone or tablet computer . For this , the or blueprint of the environment in order to extend the 2Dalignment and the original position of the at least one first map or blueprint with the 3D physical model . Potentialobject have to be provided to or determined by the separate examples include printing physical models of buildings ordevice . Further , the separate device could be equipped with trees on a 2D blueprint of an outdoor environment , anda camera and a display showing the target area as an area 35 printing physical models of furniture on a 2D blueprint of ahighlighted by computer generated visual information in an room or office . The physical models of buildings , trees orimage or a live video captured by the camera . The position furniture may have to be printed at desired places onto theof the camera of the separate device relative to the printing 2D blueprints in order to represent a realistic or planed case ,coordinate system could be computed based on an image e . g . for room planning .captured by the camera . The methods proposed above could 40 In this regard , FIG . 1A shows an existing second objectbe applied . being a 2D paper ( denoted by 1A01 ) of a room planningThe separate device could also be equipped with a pro - having positions of 3 walls 1A05 , 1A06 , and 1A07 , a doorjector projecting a pattern or some visual effects onto the position 1A08 , a bed position 1A02 , a chair position 1A03 ,target area . To compute the position of the projector , a and a desk position 1A04 . It is possible to create 3D physicalcamera could be fixed relative to the projector with a known 45 model 1B10 of the room planning by using a 3D printer torelative transformation between the camera and the projec - make or print physical objects of walls 1B05 , 1B06 , andtor . The camera could be used to capture images in order to 1307 , door 1B08 , bed 1802 , chair 1803 , and desk 1B04compute the position of the projector . onto desired places of existing 2D paper 1A01 , as depictedIn this regard , FIG . 2D shows a 3D printing system in FIG . 1B . For the printing , virtual models of 1B05 , 1B06 ,comprising a 3D printer 2A01 , in which a processing device 50 1007 , 1B08 , 1B02 , 1B03 , and 1B04 are provided to the 3D2A06 is coupled to the 3D printer 2A01 . The processing printer . For demonstration purposes , a fourth wall of thedevice is adapted to determine the spatial placement of the room is not drawn and created in 2D paper 1A01 and 3Dexisting second object in the printing coordinate system . The physical model 1B10 .processing device could be a mobile device , such as a Alignments between existing paper 1A01 and each ofmobile phone or tablet computer . The spatial placement of 55 printed physical objects 1B05 , 1B06 , 1B07 , 1B08 , 1B02 ,the existing second object is dependent upon an alignment 1B03 , and 1B04 define their spatial relationships in 3Dbetween the at least one first object and at least part of the physical model 1B10 of the room planning . The alignmentsexisting second object and upon an original position of the may be provided automatically by analyzing the drawings ofat least one first object in the printing coordinate system paper 1A01 , e . g . detecting the desk position 1A04 in exist2A10 . As mentioned above , the original position is a posi - 60 ing paper 1A01 . The alignments may also be providedtion at which at least part of the at least one first object is to manually , for example by dragging and dropping virtualbe printed onto the existing second object . A device 2D08 , models of the physical objects to be printed relative to asuch as a projector , is coupled to or communicates with ( e . g . virtual model of existing paper 1A01 , e . g . in a 3D animationdirect communication via wireless or cable connection , or program . The virtual model of existing paper 1A01 could beindirect communication through a server the processing 65 a digital drawing of existing paper 1A01 , which may be adevice and adapted to display a target area according to the scan or an image of existing paper 1A01 captured by aspatial placement of the existing second object . When the camera . For example , an image of existing paper 1A01 that15US 9 , 776 , 364 B216is placed on printing platform 2A02 captured by camera employed to capture an image of a first part ( reference2C08 could be used as a digital virtual model of existing 2A04 ) of the 3D printer and the cup . Several computerpaper 1A01 ( see FIG . 2C ) . In one embodiment of providing vision methods could be used to determine the pose based onan alignment , a user could drag and drop a virtual model of the image , for example based on model based matchingchair 1B03 to position 1A03 of the digital drawing of 5 when a virtual model of the cup is available . In case that aexisting paper 1A01 in order to provide the alignment camera is used to capture an image for determining the pose ,between existing paper 1A01 and physical object 1B03 to be the cup has to be included in the image , but the first partprinted . Furthermore , the image captured by camera 2008 ( reference 2A04 ) of the 3D printer is not necessary to becould also be used to determine a pose of existing paper included in the image .1A01 relative to printing coordinate system 2A10 of 3D 10 If cup 2A05 is within a printing area of 3D printer 2A01 ,printer 2A01 . the 3D printer could print handle 2B06 onto the cup accordAfter an initial placement of the existing paper on the ing to the pre - determined alignment and the pose of the cup .printing platform , an image of a first part ( designated by This 3D printing physically extends the cup by a handle .reference 2A04 ) of the 3D printer and the existing paper is In order to print handle 2B06 onto a desired place of cupcaptured by a camera . A pose of the existing paper in 15 2A05 using 3D printer 2A01 , it is also possible to illuminateprinting coordinate system 2A10 could be determined an area on which the cup has to be placed on the printingaccording to the image . As the existing paper is placed on the platform . A position of the final printed handle in theprinting platform , the pose could be determined according to printing coordinate system is known by the 3D printer , as thea 2 DOF translation and 1 DOF rotation on the plane of the 3D printer could decide where to print the handle . Thus , theprinting platform . The position of camera 2008 rigidly 20 3D printer could define a preferred position of the finalmounted to the 3D printer could be pre - calibrated in the printed handle . Having the pre - determined alignmentprinting coordinate system , e . g . in an off - line calibration between the handle and the cup and the preferred position of( before the actual printing process ) . In case that camera the final printed handle , a desired position where the cup has2C08 is used to capture an image for determining the pose to be placed in the printing coordinate system can beof the existing paper relative to the printing coordinate 25 determined . Then , the intersection between the cup at thesystem , the image has to include at least part of the existing desired position and the printing platform defines an area . Aspaper , but the first part ( reference 2A04 ) of the 3D printer is a position of the final printed handle could be arbitrarilynot necessary to be included in the image . defined by the 3D printer theoretically , it is possible toThe determined pose of the existing paper may indicate choose a position in which the cup has to be placed on thethat the existing paper is not placed within a printing area of 30 printing platform , e . g . area 2D09 on printing platform 2A02 .the 3D printer . In this case , the existing paper has to be FIG . 2D shows that area 2009 is illuminated visually onre - placed relative to the 3D printer and another pose of the printing platform 2A02 , e . g . by a projector 2D08 . In prinexisting paper has to be determined for the re - placed posi - ciple , the illumination of area 2D09 may be realized by lighttion . This may be repeated until the existing paper is placed sources embedded in the platform or using a projector towithin the printing area . 35 project a pattern onto the platform .If existing paper 1A01 is within the printing area , the 3D There may exist collisions between existing objects orprinter may print physical objects 1B05 , 1B06 , 1B07 , 1B08 , printed objects and a movable part of a 3D printer ( e . g .1B02 , 1B03 , and 1B04 onto the existing paper , which printer head ) during a printing process . Cameras may also beextends the 2D existing paper to 3D physical model 1B01 of employed to detect or predict the collisions .the room planning . 40 A 3D printer could print or produce a real object , whichAnother illustrative example of printing objects onto an is physical and tangible , from a virtual model of the object .existing object using a 3D printer is to print or make a handle Surface texture of the printed object is depending on mateonto an existing cup for enhancing usability of the existing rials used by the printer for printing . The surface texture ofcup . the printed object cannot be physically changed or modifiedIn this regard , FIG . 2A shows that a cup 2A05 is placed 45 after the object is completely printed . There may be a needon a printing platform 2A02 of 3D printer 2A01 for printing to visually augment a surface texture of a printed objector making a handle on an outer surface of the cup by using without re - printing another physical object from the samethe 3D printer . FIG . 2B shows the completed object with virtual model with different materials .handle 2B06 printed on the outer surface of the cup 2A05 . Augmented reality ( AR ) could be employed to visuallyA pre - determined alignment between the handle and the 50 augment the printed real object by providing an AR visualcup may be provided to determine where the handle is to be ization of overlaying computer - generated virtual informacreated on the cup . In this example , the pre - determined tion ( i . e . computer - generated image ) with a view of thealignment defines that the handle has to be created on the printed object or a part of the printed object . The virtualouter surface of the cup , or even in a particular area on the information can be any type of visually perceivable dataouter surface . The alignment may be manually defined in a 55 such as texture , texts , drawings , videos , or their combina3D animation software by manipulating a spatial relation - tion . The view of the printed object or the part of the printedship between virtual models of the handle and the cup . The object could be perceived as visual impressions by user ' svirtual model of the handle is normally available to the eyes and / or be acquired as an image by a camera .processing device and 3D printer , respectively , as the 3D The overlaid information of the computer - generatedprinter would need it for printing a physical object from its 60 image and the real object can be seen by the users in avirtual model . The virtual model of the cup may be pre - well - known optical see - through display having semi - transknown or known from a reconstruction using at least two parent glasses . The user then sees through the semi - transcamera images . The virtual model of the cup may also be parent glasses the real object augmented with the computergenerated from a camera image with depth information . generated image blended in in the glasses . The overlay of theIn order to determine a pose of cup 2A05 placed on 65 computer - generated image and the real object can also beprinting platform 2A02 in printing coordinate system 2A10 seen by the users in a video see - though display having aof 3D printer 2A01 ( see FIG . 2A ) , a camera 2A08 could be camera and a normal display device . The real object is17US 9 , 776 , 364 B218captured by the camera and the overlay is shown in the The part of the 3D printer has a known position relative todisplay to the users . The overlay of the computer - generated the 3D printer . Then , the location of the projector could beimage and the real object may also be realized by using a estimated based on the 2D coordinates of the visual patternprojector to project the computer computer - generated image in the projector coordinate system and corresponding imageonto the real object . 5 points of the visual pattern in the image .The AR visualization could run on a mobile device In order to overlay computer - generated virtual informa equipped with a camera . The equipped camera could capture tion with an image of the printed object captured by a an image as the view of the at least part of the real object . The mobile device may further have semi- transparent camera , it is also possible to directly compute the camera glasses for the optical see - through , or a normal display for 10 pose of the image with respect to the printed object based on the video see - though , or a projector for projecting the a virtual model of the printed object and the image using computer computer - generated image . computer vision methods. This does not require the printedIn order to overlay the computer - generated image with the object staying at its original place .real object at desired positions within the view captured by Although this invention has been shown and describedthe eve or the camera , or project the computer - generated 15 with respect to the detailed embodiments thereof , it will beimage onto desired surfaces of the real object using the understood by those skilled in the art that various changes inprojector , the camera of the mobile device could be used to form and detail may be made without departing from thedetermine a pose of the camera , or the eye , or the projector spirit and scope of the invention .with respect to the real object . It is particularly necessary tofirst determine a pose of the camera with respect to the real 20 What is claimed is :object based on an image captured by the camera . 1 . A method for instructing a 3D printing system comA printing coordinate system of the 3D printer defines a prising a 3D printer having a printing coordinate systemcoordinate system for a 3D printing process of printing the operable to print at least one first object onto an existingobject . Components related to the 3D printing process , e . g . object , the method comprising :a print head of the printer or a part of the print head , have 25 obtaining , by at least one camera , at least one imageknown positions in the printing coordinate system . The representing at least a part of an existing object ;original position of the printed real object ( i . e . , no move determining a camera pose of the at least one cameraments occurred after the corresponding 3D printing process relative to the existing object when the at least oneis complete ) could be known in the printing coordinate image is captured ;system . Therefore , when the printed real object stays at the 30 determining an alignment between at least part of theoriginal place , the pose of the camera or of the eyes with existing object and at least part of a first object to berespect to the printed object could be computed according to printed on the existing object based , at least in part , ona pose of the camera or the eyes in the printing coordinate the determined camera pose ;system . Several methods are disclosed in the presented determining a pose of the existing object relative to ainvention for determining a pose of a camera in the printing 35 printing coordinate system according to the at least onecoordinate system . image ; andWhen the view is captured as an image by the camera , the directing a 3D printer to print at least part of the at leastcaptured image may also be used to determine a camera pose one first object onto the existing object according to theof the image with respect to the real object , i . e . the pose of pose and the alignment .the view with respect to the real object . When the view is 40 2 . The method according to claim 1 , wherein the at leastcaptured by the eye , in addition to determining the camera one image further represents a first part of the 3D printerpose , it further needs a spatial relationship between the eyes having a known spatial relationship relative to the printingand the camera or between an eye or head orientation coordinate system .detection system and the camera for determining the pose of 3 . The method according to claim 2 , further comprising :the eye with respect to the real object . 45 computing a translation and a rotation between the firstAnother embodiment for determining the pose of an eye part of the 3D printer and the existing object in awith respect to the real object is to determine a pose of the coordinate system of the at least one image .eye in the printing coordinate system , wherein an eye or 4 . The method according to claim 1 , further comprising :head orientation detection system may be placed at a known obtaining at least two images of the existing objectposition in the printing coordinate system and used to detect 50 captured by the at least one camera , and reconstructingorientation of the eye . Eberl et al . in references [ 5 , 6 ] a 3D shape of at least part of the existing object fromdisclose methods and systems for determining orientation of the at least two images ,an eye . wherein the alignment is determined based at least in partFor using the projector to project the computer - generated on the reconstructed 3D shape .image onto the real object , in addition to determining the 55 5 . The method according to claim 1 , wherein determiningcamera pose , a spatial relationship between the projector and the camera pose comprises determining the camera posethe camera should be provided for determining a pose of the according to a virtual model of the existing object orprojector relative to the real object . according to a visual marker rigidly fixed relative to theIt is also possible to mount the projector to the 3D printer existing object .at a known location relative to the 3D printer . Then , the pose 606 . The method according to claim 1 ,of the projector relative to the real object printed by the 3D wherein the at least one camera is placed at a fixedprinter at its original position can be directly obtained . position relative to the printing coordinate system .The location of the projector could be pre - known or be 7 . The method according to claim 6 , wherein the at leastcalibrated in an off - line calibration procedure . For example , one camera is mounted to the 3D printer .the projector projects a visual pattern on the printing plat - 65 8 . The method according to claim 6 , further comprisingform of the 3D printer . The projected visual pattern and a computing a pose of the at least one camera in the printingpart of the 3D printer are captured as an image by a camera . coordinate system in a calibration procedure .??US 9 , 776 , 364 B219 209 . The method according to claim 1 , further comprising : obtain , by at least one camera , at least one image repredetermining the camera pose of the at least one camera senting at least a part of an existing object ;when capturing the at least one image relative to the determine a camera pose of the at least one cameraprinting coordinate system using a tracking system by relative to the existing object when the at least onecomputing a pose of the at least one camera and a pose 5 image is captured ;of the printing coordinate system in a tracking coordi determine an alignment between at least part of thenate system of the tracking system . existing object and at least part of a first object to be10 . The method according to claim 1 , wherein the existing object is within a printing space of the 3D printer. printed on the existing object based , at least in part, on 11 . The method according to claim 1 , wherein determin - 10 the determined camera pose ; ing an alignment between at least part of the first object and determine a pose of the existing object relative to aat least part of the existing object comprises determining the printing coordinate system according to the at least onealignment according to a virtual model of the existing object image ; andand a virtual model of the first object . direct a 3D printer to print at least part of the at least one12 . The method according to claim 11 , wherein the virtual 15 first object onto the existing object according to themodel of the existing object is computed according to the at pose and the alignment .least one image . 15 . The 3D printing system according to claim 13 ,13 . A 3D printing system adapted for printing at least one wherein the at least one image further represents a first partfirst object onto an existing object comprising : of the 3D printer having a known spatial relationship relativea 3D printer provided with a printing coordinate system ; 20 to the printing coordinate system .a processing device ; and 16 . The 3D printing system according to claim 15 , furthera memory comprising instructions which , when executed comprising instructions to :by the processing device , cause the processing device compute a translation and a rotation between the first partof the 3D printer and the existing object in a coordinateobtain , by at least one camera , at least one image repre - 25 system of the at least one image .senting at least a part of an existing object ; 17 . The 3D printing system according to claim 13 , furtherdetermine a camera pose of the at least one camerao comprising instructions to :relative to the existing object when the at least one obtain at least two images of the existing object capturedimage is captured ; by the at least one camera , and reconstructing a 3Ddetermine an alignment between at least part of the 30 shape of at least part of the existing object from the atexisting object and at least part of a first object to be least two images ,printed on the existing object based , at least in part , on wherein the alignment is determined based at least in partthe determined camera pose ; on the reconstructed 3D shape .determine a pose of the existing object relative to a 18 . The computer program product according to claim 14 ,printing coordinate system according to the at least one 35 wherein the at least one camera is placed at a fixed positionimage ; and relative to the printing coordinate system .direct the 3D printer to print at least part of the at least one 19 . The computer program product according to claim 18 ,first object onto the existing object according to the wherein the at least one camera is mounted to the 3D printer .pose and the alignment . 20 . The computer program product according to claim 18 ,14 . A computer program product comprising a non - 40 further comprising computing a pose of the at least onetransitory computer readable storage medium having com camera in the printing coordinate system in a calibrationputer readable software code sections embodied in the procedure .medium , which software code sections are configured to : * * * *to :